---
title: "Statistical Report on Qualified Immunity"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

## Setup

```{r load-packages, message = FALSE}
library(tidyverse)
library(knitr)
library(rvest)
library(lubridate)
library(infer)
library(tm)
library(broom)
library(Synth)
set.seed(460)
```

```{r load-data}
co_offenses <- read_csv("data/crime.csv")
wa_offenses <- read_csv("data/SPD_Crime_Data__2008-Present.csv")
tx_offenses19 <- read_csv("data/houston_nibrs_2019.csv")
tx_offenses20 <- read_csv("data/houston_nibrs_2020.csv")
tx_offenses21 <- read_csv("data/houston_nibrs_2021.csv")
cspd <- read_csv("data/Crime_Level_Data.csv")
fspd_offenses <- read_csv("data/fspd_offenses.csv")
nibrs_conversion <- read_csv("data/NIBRS_OFFENSE_TYPE.csv")
champaign21 <- read_csv("data/2021_champaign.csv")
champaign20 <- read_csv("data/2020_champaign.csv")
champaign19 <- read_csv("data/2019_champaign.csv")
austin_offenses <- read_csv("data/austin_offenses.csv")
full_database <- read_csv("data/crime_database.csv")
synth_complete <- readRDS("data/denver_violent_synth.Rdata") # Outdated synthetic control models
synth_complete_test <- readRDS("data/denver_violent_true.Rdata")
synth_denver_property <- readRDS("data/denver_property_synth.Rdata")
synth_denver_property_test <- readRDS("data/denver_property_true.Rdata")
```

Ct law is effective July 1, 2021.
NYC banned qualified immunity around March 2021.
New Mexico ended qualified immunity 

## Introduction and Background

Qualified immunity is a court-established doctrine that shields government officials from personal liability for constitutional violations unless the officials violated clearly established laws (https://www.lawfareblog.com/what-qualified-immunity-and-what-does-it-have-do-police-reform). After the killing of George Floyd sparked movements against police violence around the country, many activists directed their attention towards qualified immunity as a subject of reform. Activists argued that qualified immunity prevents police officers from being held accountable for excessive uses of force within civil court. Supporters of qualified immunity argued that efforts to limit qualified immunity would prevent police officers from effectively performing their job out of fear of frivolous lawsuits. In this statistical report, we aim to provide preliminary data-driven insights on the effects of recently passed qualified immunity reform on violent and property crime rates in major urban jurisdictions.

Four states have passed measures to limit qualified immunity: Colorado, Connecticut, New Mexico, and New York. Of those states, Colorado passed its reform the earliest, with its measure taking effect June 19, 2020. As a result, we decided to analyze Colorado crime data to determine the effects of qualified immunity on crime rates. In particular, our research question was as follows: Was the passage of qualified immunity reform in Colorado in June of 2020 correlated with significantly larger proportional increases in average daily violent and property crime incidents compared to increases in control jurisdictions? Because statewide data for 2020 and 2021 YTD from Colorado was not publicly available, we further narrowed the scope of our analysis to Denver, Colorado Springs, and Aurora, the three largest jurisdictions within Colorado.

Although we attempt to establish some level of causation in this study through the use of a synthetic control method, we lack the volume of observational data needed to successfully establish causation. In particular, we are missing observations on several key lurking variables, including the effects of COVID on poverty rates in each jurisdiction, 2020 and 2021 census data, community attitudes towards policing as a result of the George Floyd protests, amidst several other control variables. Much of this data will only be released a few years from now, severely limiting the contours of the present analysis. However, due to the prescience of the qualified immunity question and the need for data within the debate, we decided to produce this preliminary report to at least illustrate the plausible effects of qualified immunity on crime rates in Colorado. None of the findings in this report should be interpreted as demonstrating a conclusive causal relationship between qualified immunity reform and crime.

## Overview of Available Data

Many of our Methodology choices can only be understood in the context of the available data and policy context at our disposal. 

We obtained three different types of data from three sources, almost entirely through data released from official sources (with the exception of land area data, which was obtained from a website reporting census data but may have errors). First, we received socioeconomic indicator data from the 2011-2019 American Community Survey estimates as found through the census data website. The predictor data we utilized was organized "by Place," meaning the data was largely aggregated in terms of local unit boundaries (towns, cities, CDPS, etc). This data was collected with the intention of serving as crime predictor data, a use that will be described further in the "Methodology" section. Unfortunately, at the time of the creation of this report, neither 2020 nor 2021 census data had been publicly released. Second, we collected crime rate data by state by city through the UCR Crime in the United States Reports released by the FBI. This data was complete from 2011-2020, and the first 3 quarters of both 2020 and 2021 had been released in the Quarterly UCR Report from roughly 155 large agencies (limited by the number of agencies that reported their crime rates). This data included statistics on jurisdiction population, violent crime numbers, property crime numbers, and numbers for individual crimes (such as forcible rape, nonnegligent homicide/murder, larceny, etc). The quarterly data was unfortunately not disaggregated by quarter, which presented problems later down the line in Methodology A, as the 2020 data incorporated 2 quarters without qualified immunity legislation effect in Denver and 1 quarter after the passage of the qualified immunity legislation. Third, we received incident level crime data by downloading the data from various agency websites and submitting FOIA requests for agencies that had not released their data (such as Champaign Police Department). Several times, these FOIA requests returned data that was unfeasible to use (such as PDF reports of individual crimes), were too costly (totaling greater than $100 for smaller agencies), or were flatly denied on the basis that data was not kept or that state FOIA laws only permitted in-state residents to make FOIA requests (in the case of Clarksville). As a result, the usefulness of FOIA requested data was incredibly limited; however, we incorporated the data that we could obtain using this method into the analysis. The incident-level crime data gave us daily incident crime numbers for various offenses. We categorized incidents into violent and property crimes based on the UCR definitions (Footnote).

In sum, the data that we could obtain was extremely limited in scope, largely due to the combination of limited fiscal/temporal resources, difficulty in obtaining data from police departments, and late releases of census and UCR data. These data limitations then significantly harmed the soundness of the analysis and forced the methodology to deviate significantly from its ideal form. 

## Methodology

In this study, we employed two different methodologies, one to increase the accuracy of the treatment date and the other to increase the total completeness of the data. We have incorporated findings from both methodologies with clear delineations as to which methodologies resulted in which findings. Both methodologies suffer from severe flaws, but we believe the insights from both methodologies may still be important in the discussion of qualified immunity and police accountability. Limitations will be more thoroughly discussed in the "Limitations" section of this report.

In both methodologies, we employed, to varying extents, a synthetic control methodology as described by Abadie in his article "Using Synthetic Controls: Feasibility, Data Requirements, and Methodological Aspects." In a synthetic control method, researchers create a weighted average of jurisdictions and data points with the goal of minimizing the distance between the weighted average and the true jurisdiction's pre-treatment predictor and response values. The synthetic control method has the advantage of systematically identifying the strongest control jurisdictions based on predictor numbers over time, as opposed to manually identifying a geographically close jurisdiction and claiming the existence of sufficient connection to isolate the effects of the policy intervention, thus removing the effects of researcher bias from the analysis. Generally, the synthetic control method is then followed by a series of placebo synthetic control constructions to determine if the post-treatment to pre-treatment MSPE (root mean squared prediction error) ratio for the treated jurisdiction is extreme compared to those of placebo synthetic controls (https://mixtape.scunning.com/synthetic-control.html). If employed successfully, the synthetic control method can successfully prove the existence of a causal connection between different variables.

### Sampling Methodology

Using data provided by the FBI UCR reports, we created a dataset of about 100 jurisdictions and tracked their violent and property crime numbers from 2011 to the first 3 quarters of 2021. Jurisdictions were chosen on the basis of two criteria: First, the jurisdictions' violent and property crime numbers must have been published every year (from 2011 to 2021) by the UCR, including in the UCR's 2021 quarterly crime report. Because the UCR's 2021 quarterly crime report only received numbers from less than 50% of agencies and only published figures from jurisdictions greater than 100,000 in population, the sample of jurisdictions is influenced by some self-selection sampling bias; those jurisdictions that chose not to report figures for one of the years would be automatically excluded. Second, jurisdictions must have been greater than 85K in population according to UCR estimates for every year from 2011 to 2020 (no population data for 2021). This measure is meant to exclude excessively small jurisdictions at the beginning time period that experienced extreme population growth. The number "85,000" was chosen, in part, as an arbitrary value for a jurisdiction that could experience average population growth from 2011 to reach at least 100,000 by 2020. The second selection criterion suffers from some arbitrariness; however, the criterion only excludes 4 jurisdictions from the analysis, each of which were likely too small to provide significant insight. 

After compiling the database of crime numbers, we then compiled a set of yearly socioeconomic indicators from each jurisdiction to serve as predictor values for the 'Synth' package to average when creating a synthetic control. In particular, we chose indicators on the basis of sociological evidence that such indicators could serve as moderately strong predictors of metropolitan violent or property crime rates. Based on the results found in Wells and Weishelt's "Explaining Crime in Metropolitan and Non-Metropolitan Counties," we chose to record jurisdictions' single female-led household percentage, high school education percentage, residential stability (or percent of people living in the same property that they lived in 1 year ago), percentage of population over 18, percentage of population who is white, percentage of population who is self-employed, unemployment rate, median income, child poverty rate, percent of housing units that are owner-occupied, and population density (or population divided by land area). Certain variables recorded in the Wells and Weishelt study were excluded from our analysis because they were either found to be largely non-significant for metropolitan counties in the study (such as South vs. non-South) or were difficult to collect (such as % voting in last election). These indicators were collected by jurisdiction for 2011 to 2019 from the census tables. If a jurisdiction was missing data from any of those years on any of the collected variables, the jurisdiction was excluded from the analysis.

Certain errors occurred when combining census data with UCR data, particularly around the naming schemes of the cities. While the UCR names cities by their given names, the census data often adds addendum names such as "CDP," "city," "town," and others. We attempted to correct for these errors by erasing addendum words from census names (for instance, removing " City" from names as in the case of "Boise City, Idaho" or "Houston City, Texas"). For large jurisdictions (usually above 100000 in population), we further went back and individually corrected names to match. We believe we caught most of these errors, but inevitably some errors slipped through the cracks, leading to randomly lost data. Regardless, we find it unlikely that these random errors significantly hindered our analysis. 

Because we lacked predictor data for 2020 and 2021, we extrapolated predictor data from 2019 to 2020 and 2021. In other words, 2020 and 2021 predictor data (outside of population and population density) were equivalent to 2019 data. Additionally, 2021 population and population density were extrapolated from 2020 population figures. We do not argue that this extrapolation is a fair representation of reality; of course, with COVID and the George Floyd protests of 2020, socioeconomic indicators in 2020 will be far different from those in 2019. Extrapolating will almost certainly skew our pre-treatment predictor averages to some extent; however, we do not think it will invalidate our results entirely. We discuss more in the "Methodology A" section what the implications of this choice will be on our results.

In the end, we had a dataset of 96 jurisdictions, with crime data from 2011 to 2021 and predictor data from 2011 to 2019. In total, our dataset had `r nrow(reduced_database_violent)` observations and 24 variables. In Table 1, we display the first 20 rows of our dataset.

```{r display-dataset}
reduced_database_violent %>% 
  slice(1:20) %>% 
  select(state, city, population)
```

We decided to split our analysis into violent and property crime analysis for similar reasons as Wells and Weishelt did in their study. There is no evidence that violent and property crime trends are parallel, and ordinarily, property crime numbers would constitute 90% of the total crime rate. Additionally, because the UCR primarily reports property and violent crime numbers, property and violent crime numbers would already be standardized before we began our wrangling process.

### Methodology A: Approximating the Ideal Synthetic Control Methodology

In our first methodology, we analyzed 3 treated jurisdictions (Denver, Colorado Springs, and Aurora) and included roughly 91 control jurisdictions. The treated jurisdictions were chosen on the basis that they were the 3 largest cities within Colorado. We excluded cities in Connecticut, as they passed their own version of the qualified immunity bill around the same time as Colorado, and their law took effect in June of 2021, skewing the 2021 results. We did not need to further exclude New Mexico and New York City, as such jurisdictions were missing data and did not appear in our final dataset, regardless. 

Using the `Synth` package, we created synthetic controls of each of the 3 treated jurisdictions for both violent and property crime rates. To determine the variables most helpful in explaining violent and property crime rate shifts in our dataset, we created logarithmic linear models and used AIC model selection processes to remove variables that were generally not helpful in explaining shifts in violent and property crime rates. The model selection process, along with the reason we used logarithmic linear models, is further described in Appendix 1. In the end, we removed median income as a predictor from violent crime analysis and owner-occupied housing and single female-led household percentage from property crime analysis.

When creating synthetic controls, we included all pretreatment time periods but optimized over 2012 to 2019, allowing the "Synth" function to automatically calculate the pre-treatment MSPE over those 8 years. We specified the pretreatment time period (time.predictors.prior) to be 2011 to 2020. Although 2020 was the year that the qualified immunity law was passed in Colorado, the function we used to calculate MSPE ratios was the "generate.placebos" function from the SCtools package, which included the final pretreatment year and the posttreatment years in calculating the post-treatment MSPE. Thus, although the pretreatment time period was specified to be 2011 to 2020, for functional purposes, 2012 to 2019 were the years relevant to the pre-treatment MSPE calculation, and 2020-2021 were the years relevant to the post-treatment MSPE calculation. Additionally, we specified for the package to employ every available optimization method and choose the best-performing method. We ended by creating 6 different synthetic controls, two for each Colorado jurisdiction, and within each jurisdiction, one for violent crime rates and one for property crime rates.

To determine the significance of our findings, we calculated the "MSPE (mean squared prediction error) ratio" for each of the synthetic controls. In other words, we averaged the squared amount that the synthetic violent or property crime rates differed from the observed violent or property crime rates over the optimized pretreatment time period, given by the `Synth` function as the `loss.v` value. We then averaged the squared amount that the synthetic violent or property crime rates differed from the observed violent or property crime rates over the post-treatment time period. To control for jurisdictions where the synthetic model was not a great fit to begin with, we then divided the post-treatment MSPE by the pre-treatment MSPE, creating an MSPE ratio. Theoretically, if the intervention had a significant effect on the property or violent crime rates in the treated jurisdictions, we should see significant increases in crime rates in 2020 and 2021 exceeding those of the synthetic control, and thus, the MSPE ratio of those jurisdictions should be high. However, because there is no objective metric for what a "high enough" MSPE ratio is, we further created placebo synthetic controls for every control jurisdiction in the dataset and calculated MSPE ratios for each placebo synthetic control. (FOOTNOTE) If the MSPE ratio of the treated jurisdiction was greater than 95% of placebo MSPE ratios, we concluded that the MSPE ratio of the treated jurisdiction was high enough to be statistically significant. The interpretations of such a conclusion will be further discussed in the "Results" section. 

The synthetic control methodology that we employed suffered from several limitations. First, as noted in the "Sampling Methodology" section, we extrapolated predictor values from 2019 to 2020 and 2021. This biased the averages used when constructing the synthetic control. Since 2020 was included in the pretreatment time section, we functionally doubled the role of 2019 in calculating predictor averages for the treated jurisdiction for the synthetic jurisdiction to emulate. We do not believe this should, alone, invalidate our analysis however. Since the 2020 predictors data is only used in calculating an overall average of the predictors that the synthetic jurisdiction should approximate - and not to serve as predictors that should be held constant from year to year to isolate the effects of the intervention - the extrapolated 2020 data would only cause the synthetic control methodology to create weighted averages that matched treated jurisdictions' 2019 data above other older years. For example, if researchers attempted to control the 2020 and 2021 MSPE for the predictor variables using the 2019 data, such an effort would clearly be invalid, as 2019 unemployment and child poverty rates clearly cannot be used to adjust for 2020 and 2021 data. However, because we employ a synthetic control methodology and do not calculate MSPEs differently based on predictor values, we do not suffer from such limitations. The methodology merely averages the predictor values of the treated jurisdiction over the pretreatment time period for the synthetic control to match, but does not attempt to hold such predictors constant from year to year or control for yearly shifts in those predictors. Thus, the skew created by such a flaw is minimal. 

Second, the time of the treatment is not effectively accounted for by the synthetic control methodology. The passage of the qualified immunity bill in Colorado occurred in the middle of 2020; however, we do not have quarterly data by which we could isolate the 2 quarters of 2020 without the influence of the policy intervention from the 2 quarters influenced by the intervention. Instead, we simply sort 2020 and 2021 as broadly falling under the post-treatment time frame, operating on the assumption that if the qualified immunity legislation affected violent and property crime rates in the Colorado jurisdictions, the increase in violent and property crime rates for the whole of 2020 would be greater than those of treated jurisdictions. Unfortunately, such an assumption is not necessarily true, as 2020 introduced a series of different factors, ranging from COVID to the George Floyd protests, each of which influenced  jurisdictions' crime rates in unknown ways. As a result, we are hesitant to derive a causal conclusion from any of our analysis; our findings could very well be interpreted in several different lights, including that COVID impacted Colorado jurisdictions' crime rates harder than other jurisdictions, or that police agencies in Colorado passed 2020 policies different from those of other jurisdictions. We attempt to solve this problem in Methodology B at the cost of other significant methodological limitations.



















In practice, however, we faced critical data limitations that made it impossible to run the most statistically robust version of the synthetic control method. Because we lacked widely available 2020-21 post-treatment crime and census data (we only had that data for very specific jurisdictions), we could not create a series of placebo synthetic controls with post-treatment RMSPE values to compare the RMSPE ratio of the treated jurisdiction with. In addition, we only had access to a very small number of time periods (2011-19) and included an enormous sample of jurisdictions within the donor pool (many of which were substantially different from the treated jurisdictions) due to the rarity by which we could obtain data from police departments, significantly increasing the potential for bias. To continue the data analysis under these limitations, we primarily utilized the synthetic control methodology to identify similar jurisdictions to Denver or Colorado Springs and to provide weights for some of those jurisdictions.

Because no database of city predictors and violent/property crime rates over 2011-2019 previously existed, we created a new database from scratch. Using ACS census data from 2011 to 2019, we recorded each jurisdiction's name, single female-led family household percentage, percentage of the population who graduated high school, percentage of the population who lived in the same house they lived in a year ago, percentage of the population who were over 18, percentage of the population who were white, percentage of the population who were self-employed, unemployment rate, median income, child poverty rate, and the percentage of housing units occupied by their owners. Each of these predictors had been identified as possible or significant predictors of crime within metropolitan and nonmetropolitan counties in a study published by researchers Wells and Weishelt (Explaining Crime in Metropolitan and Non-Metropolitan Counties). We then combined the city predictor data with violent crime, property crime, and population statistics from UCR Crime in the United States fact tables. Our final full database included over 83000 observations and 20 variables, each observation representing a jurisdiction at a particular year. We then filtered the database to only include cities above 50000 in population to remove small rural jurisdictions that would likely not match the dynamics of more urban areas like Denver. Additionally, we removed jurisdictions with missing data on violent/property crime rates or missing yearly data.

Since publicly available data was not available for 2020-2021 from either the UCR or the ACS, we utilized the Synth package to create a synthetic control model for Denver and Colorado Springs from 2011-2019. We optimized the synthetic control model for 2016 to 2019 to obtain jurisdictions that could follow the most recent trends in both Denver and Colorado Springs. We then identified the top 5 jurisdictions with the highest weights and reran the synthetic control model with only those jurisdictions to recalculate the weights. With those identified control jurisdictions, we submitted requests for incident-level crime data from those departments for 2019-2021. When those requests were either unanswered or denied (as in the case of Ann Arbor Police Department), we removed the city from the synthetic control model and reran the model until we obtained at least four police departments with accessible incident level crime data whose plot looked at least somewhat similar to the plots of the treated jurisdictions (Denver and Colorado Springs).

We subdivided all 2019-2021 incident-level crime data into property and violent crimes based on UCR definitions. In particular, murder and nonnegligent homicide, aggravated assault, robbery, and forcible rape (including sexual assault with an object, fondling, and forcible sodomy) were identified as violent crimes. We categorized larceny charges, burglary, damage/destruction of property, arson, shoplifting, pocket-picking, and motor vehicle theft charges as property crimes. We calculated the daily numbers of violent and property offenses for June of 2019 to June of 2020 (before qualified immunity reform) and June of 2020 to June of 2021 (after qualified immunity reform) in control and treated jurisdictions. We then subtracted the daily numbers of violent and property offenses in the 2019-20 time period from the 2020-21 time period and divided by the total number of violent or property offenses in the 2019-20 time period to make the daily numbers of violent and property crimes proportionate to each jurisdiction's respective crime numbers. Finally, we created a bootstrapped null distribution assuming no true difference between the daily increases of the synthetic jurisdiction compared to Denver or Colorado Springs and calculated a p-value based on the probability of observing the real difference or greater between Denver/Colorado Springs and the respective synthetic control difference based on the null distribution.

This methodology had a few other critical limitations. First, because of the lack of 2020 and 2021 census data, we could only identify jurisdictions similar to either Denver or Colorado Springs until 2019 which is no guarantee that those similarities in control predictors continued until 2020 and 2021. In addition, since we did not have access to UCR data for 2020 and 2021, we had to use 2011-2019 weights in 2020 and 2021 calculations, which may extrapolate beyond the capabilities of the synthetic control, since the trends between the predictor variables and the responsive crime rates may not continue into 2020 and 2021 (which also introduced other variables, such as the George Floyd protests, that influenced crime rates). Second, because of the several denied requests (especially from Ann Arbor and Clarksville Police Departments), we were forced to rely partially on convenience sampling in order to successfully carry out the study. Despite this, the plots comparing the synthetic control property/violent crime rates with the Denver property/violent crime rates look strong enough to indicate that the synthetic controls at least partially match the crime trends of the treated jurisdictions even when certain jurisdictions were removed due to lack of data. Third, because we needed to determine if the increases between the 2019-20 time period and 2020-21 time period were significantly greater than increases in control jurisdictions, we were forced to employ a test where we subtracted daily crimes in one time period from daily crimes in another time period. This method may have substantially exaggerated the standard deviation of violent and property crimes, since daily fluctuations in crime do not remain constant over the course of a year. The test may have been more successful on a monthly level, but we did not have enough monthly difference data to successfully arrive at statistical conclusions through simulation. Fourth, because we had to standardize the daily crime numbers by dividing crime numbers from some relative figure for each jurisdiction (in this case, the total number of offenses in the 2019-20 time period), smaller jurisdictions disproportionately influenced the variance of the synthetic control, since daily fluctuations of 1-2 offenses were much greater when standardized compared to larger jurisdictions. See Appendix 1 for further details.