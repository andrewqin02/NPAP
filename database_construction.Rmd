---
title: "FBI Database Compilation"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Setup

```{r load-packages, message = FALSE}
library(tidyverse)
library(knitr)
library(rvest)
library(lubridate)
library(infer)
library(readxl)
library(tm)
library(broom)
library(Synth)
library(rms)
library(SCtools)
set.seed(460)
```

## Load Crime Data

```{r crime-data, message = FALSE}
crime_11 <- read_csv("fbi/2011_crimes_bycity.csv")
crime_12 <- read_csv("fbi/2012_crimes_bycity.csv")
crime_13 <- read_csv("fbi/2013_crimes_bycity.csv")
crime_14 <- read_csv("fbi/2014_crimes_bycity.csv")
crime_15 <- read_csv("fbi/2015_crimes_bycity.csv")
crime_16 <- read_csv("fbi/2016_crimes_bycity.csv")
crime_17 <- read_csv("fbi/2018_crimes_bycity.csv")
crime_18 <- read_csv("fbi/2018_crimes_bycity.csv")
crime_19 <- read_csv("fbi/2019_crimes_bycity.csv")
crime_20 <- read_csv("fbi/2020_crimes_bycity.csv")
crime_21 <- read_csv("fbi/2021_quarterly.csv")
```

## Crime Data Wrangling

```{r slice-footnotes}
crime_11 <- crime_11 %>% 
  slice(1:9314)
crime_12 <- crime_12 %>% 
  slice(1:9491)
crime_13 <- crime_13 %>% 
  slice(1:9292)
crime_14 <- crime_14 %>% 
  slice(1:9347)
crime_15 <- crime_15 %>% 
  slice(1:9395)
crime_16 <- crime_16 %>% 
  slice(1:9579)
crime_17 <- crime_17 %>% 
  slice(1:9579)
crime_18 <- crime_18 %>% 
  slice(1:9252)
crime_19 <- crime_19 %>% 
  slice(1:8105)
crime_20 <- crime_20 %>% 
  slice(1:7689)
crime_21 <- crime_21 %>% 
  slice(1:318)

```


```{r fill-msa-names}
crime_11 <- crime_11 %>% 
  mutate(year = "2011") %>% 
  fill(State, .direction = "down")

crime_11$State <- crime_11$State %>% 
  str_replace("ALABAMA2", "ALABAMA")

crime_12 <- crime_12 %>% 
  mutate(year = "2012") %>% 
  fill(State, .direction = "down")

crime_13 <- crime_13 %>% 
  mutate(year = "2013") %>% 
  fill(State, .direction = "down")

crime_14 <- crime_14 %>% 
  mutate(year = "2014") %>% 
  fill(State, .direction = "down")

crime_15 <- crime_15 %>% 
  mutate(year = "2015") %>% 
  fill(State, .direction = "down")

crime_16 <- crime_16 %>% 
  mutate(year = "2016") %>% 
  fill(State, .direction = "down")

crime_17 <- crime_17 %>% 
  mutate(year = "2017") %>% 
  fill(State, .direction = "down")

crime_18 <- crime_18 %>% 
  mutate(year = "2018") %>% 
  fill(State, .direction = "down")

crime_19 <- crime_19 %>% 
  mutate(year = "2019") %>% 
  fill(State, .direction = "down")

crime_20$State <- crime_20$State %>% 
  str_replace("Alabama3", "Alabama")

names(crime_20)[4] <- names(crime_11)[4]
names(crime_20)[9] <- names(crime_11)[9]

crime_20 <- crime_20 %>% 
  mutate(year = "2020") %>% 
  fill(State, .direction = "down")

crime_21 <- crime_21 %>% 
  fill(Population, .direction = "down") %>% 
  filter(City != "Atlanta" & City != "Mobile" & City != "Philadelphia") %>% 
  mutate(Year = as.character(Year)) # All states with missing 2020 data 
crime_21$State <- toupper(crime_21$State)
names(crime_21)[3] <- "year"
names(crime_21)[5] <- "Violent\ncrime"
names(crime_21)[10] <- "Property\ncrime"
names(crime_21)[6] <- "Murder and\nnonnegligent\nmanslaughter"
names(crime_21)[7] <- "Forcible\nrape"
names(crime_21)[9] <- "Aggravated\nassault"
names(crime_21)[13] <- "Motor\nvehicle\ntheft"
names(crime_21)[12] <- "Larceny-\ntheft"

crime_21 <- crime_21 %>% 
  filter(year == "2021")

```


```{r combine-data}
all_crimes <- full_join(crime_11, crime_12)
all_crimes <- full_join(all_crimes, crime_13)
all_crimes <- full_join(all_crimes, crime_14)
all_crimes <- full_join(all_crimes, crime_15)
all_crimes <- full_join(all_crimes, crime_16)
all_crimes <- full_join(all_crimes, crime_17)
all_crimes <- full_join(all_crimes, crime_18)
all_crimes <- full_join(all_crimes, crime_19)
all_crimes <- full_join(all_crimes, crime_20)
all_crimes <- full_join(all_crimes, crime_21) #can solve forcible rape/rape1 problem by just changing rape1 name to forcible rape
```

```{r wrangle-all-crimes}
names(all_crimes)[1] <- "state"
names(all_crimes)[2] <- "city"
names(all_crimes)[3] <- "population"
names(all_crimes)[4] <- "violent_crime"
names(all_crimes)[9] <- "property_crime"
all_crimes <- all_crimes %>%
  select(state, city, population, violent_crime, property_crime, year) %>% 
  mutate(violent_crime_rate = violent_crime / population * 100000) %>% 
  mutate(property_crime_rate = property_crime / population * 100000)

all_crimes$state <- removeNumbers(all_crimes$state)
all_crimes$city <- removeNumbers(all_crimes$city)
all_crimes$state <- str_remove(all_crimes$state, ", ")
all_crimes$city <- str_remove(all_crimes$city, ", ")
all_crimes$city <- str_remove(all_crimes$city, ",")
all_crimes$state <- str_to_title(all_crimes$state)
all_crimes <- all_crimes %>% 
  mutate(year = as.numeric(year))
```


## Load Census Data

```{r load-census-data, message = FALSE}
social_acs_2011 <- read_csv("census/2011_social_acs.csv")
economic_acs_2011 <- read_csv("census/2011_economic_acs.csv")
housing_acs_2011 <- read_csv("census/2011_housing_acs.csv") 
demographic_acs_2011 <- read_csv("census/2011_demographic_acs.csv")
social_acs_2012 <- read_csv("census/2012_social_acs.csv")
economic_acs_2012 <- read_csv("census/2012_economic_acs.csv")
housing_acs_2012 <- read_csv("census/2012_housing_acs.csv") 
demographic_acs_2012 <- read_csv("census/2012_demographic_acs.csv")
social_acs_2013 <- read_csv("census/2013_social_acs.csv")
economic_acs_2013 <- read_csv("census/2013_economic_acs.csv")
housing_acs_2013 <- read_csv("census/2013_housing_acs.csv") 
demographic_acs_2013 <- read_csv("census/2013_demographic_acs.csv")
social_acs_2014 <- read_csv("census/2014_social_acs.csv")
economic_acs_2014 <- read_csv("census/2014_economic_acs.csv")
housing_acs_2014 <- read_csv("census/2014_housing_acs.csv") 
demographic_acs_2014 <- read_csv("census/2014_demographic_acs.csv")
social_acs_2015 <- read_csv("census/2015_social_acs.csv")
economic_acs_2015 <- read_csv("census/2015_economic_acs.csv")
housing_acs_2015 <- read_csv("census/2015_housing_acs.csv") 
demographic_acs_2015 <- read_csv("census/2015_demographic_acs.csv")
social_acs_2016 <- read_csv("census/2016_social_acs.csv")
economic_acs_2016 <- read_csv("census/2016_economic_acs.csv")
housing_acs_2016 <- read_csv("census/2016_housing_acs.csv") 
demographic_acs_2016 <- read_csv("census/2016_demographic_acs.csv")
social_acs_2017 <- read_csv("census/2017_social_acs.csv")
economic_acs_2017 <- read_csv("census/2017_economic_acs.csv")
housing_acs_2017 <- read_csv("census/2017_housing_acs.csv") 
demographic_acs_2017 <- read_csv("census/2017_demographic_acs.csv")
social_acs_2018 <- read_csv("census/2018_social_acs.csv")
economic_acs_2018 <- read_csv("census/2018_economic_acs.csv")
housing_acs_2018 <- read_csv("census/2018_housing_acs.csv") 
demographic_acs_2018 <- read_csv("census/2018_demographic_acs.csv")
social_acs_2019 <- read_csv("census/2019_social_acs.csv")
economic_acs_2019 <- read_csv("census/2019_economic_acs.csv")
housing_acs_2019 <- read_csv("census/2019_housing_acs.csv") 
demographic_acs_2019 <- read_csv("census/2019_demographic_acs.csv")
```
  


```{r}
social_acs_2011 <- social_acs_2011 %>% 
  select(NAME, DP02_0008PE, DP02_0066PE, DP02_0079PE) %>% 
  mutate(year = "2011")
economic_acs_2011 <- economic_acs_2011 %>% 
  select(NAME, DP03_0049PE, DP03_0009PE, DP03_0062E, DP03_0074PE, DP03_0129PE) %>% 
  mutate(year = "2011")
housing_acs_2011 <- housing_acs_2011 %>% 
  select(NAME, DP04_0045PE) %>% 
  mutate(year = "2011")
demographic_acs_2011 <- demographic_acs_2011 %>% 
  select(NAME, DP05_0018PE, DP05_0072PE) %>% 
  mutate(year = "2011")
social_acs_2012 <- social_acs_2012 %>% 
  select(NAME, DP02_0008PE, DP02_0066PE, DP02_0079PE) %>% 
  mutate(year = "2012") %>% 
  slice(-1)
economic_acs_2012 <- economic_acs_2012 %>% 
  select(NAME, DP03_0049PE, DP03_0009PE, DP03_0062E, DP03_0074PE, DP03_0129PE) %>% 
  mutate(year = "2012") %>% 
  slice(-1)
housing_acs_2012 <- housing_acs_2012 %>% 
  select(NAME, DP04_0045PE) %>% 
  mutate(year = "2012") %>% 
  slice(-1)
demographic_acs_2012 <- demographic_acs_2012 %>% 
  select(NAME, DP05_0018PE, DP05_0072PE) %>% 
  mutate(year = "2012") %>% 
  slice(-1)

social_acs_2013 <- social_acs_2013 %>% 
  select(NAME, DP02_0008PE, DP02_0066PE, DP02_0079PE) %>% 
  mutate(year = "2013") %>% 
  slice(-1)
economic_acs_2013 <- economic_acs_2013 %>% 
  select(NAME, DP03_0049PE, DP03_0009PE, DP03_0062E, DP03_0074PE, DP03_0129PE) %>% 
  mutate(year = "2013") %>% 
  slice(-1)
housing_acs_2013 <- housing_acs_2013 %>% 
  select(NAME, DP04_0045PE) %>% 
  mutate(year = "2013") %>% 
  slice(-1)
demographic_acs_2013 <- demographic_acs_2013 %>% 
  select(NAME, DP05_0018PE, DP05_0072PE) %>% 
  mutate(year = "2013") %>% 
  slice(-1)

social_acs_2014 <- social_acs_2014 %>% 
  select(NAME, DP02_0008PE, DP02_0066PE, DP02_0079PE) %>% 
  mutate(year = "2014") %>% 
  slice(-1)
economic_acs_2014 <- economic_acs_2014 %>% 
  select(NAME, DP03_0049PE, DP03_0009PE, DP03_0062E, DP03_0074PE, DP03_0129PE) %>% 
  mutate(year = "2014") %>% 
  slice(-1)
housing_acs_2014 <- housing_acs_2014 %>% 
  select(NAME, DP04_0045PE) %>% 
  mutate(year = "2014") %>% 
  slice(-1)
demographic_acs_2014 <- demographic_acs_2014 %>% 
  select(NAME, DP05_0018PE, DP05_0072PE) %>% 
  mutate(year = "2014") %>% 
  slice(-1)
  
social_acs_2015 <- social_acs_2015 %>% 
  select(NAME, DP02_0008PE, DP02_0066PE, DP02_0079PE) %>% 
  mutate(year = "2015") %>% 
  slice(-1)
economic_acs_2015 <- economic_acs_2015 %>% 
  select(NAME, DP03_0049PE, DP03_0009PE, DP03_0062E, DP03_0074PE, DP03_0129PE) %>% 
  mutate(year = "2015") %>% 
  slice(-1)
housing_acs_2015 <- housing_acs_2015 %>% 
  select(NAME, DP04_0046PE) %>% 
  mutate(year = "2015") %>% 
  slice(-1)
names(housing_acs_2015)[2] <- "DP04_0045PE"
demographic_acs_2015 <- demographic_acs_2015 %>% 
  select(NAME, DP05_0018PE, DP05_0072PE) %>% 
  mutate(year = "2015") %>% 
  slice(-1)

social_acs_2016 <- social_acs_2016 %>% 
  select(NAME, DP02_0008PE, DP02_0066PE, DP02_0079PE) %>% 
  mutate(year = "2016") %>% 
  slice(-1)
economic_acs_2016 <- economic_acs_2016 %>% 
  select(NAME, DP03_0049PE, DP03_0009PE, DP03_0062E, DP03_0074PE, DP03_0129PE) %>% 
  mutate(year = "2016") %>% 
  slice(-1)
housing_acs_2016 <- housing_acs_2016 %>% 
  select(NAME, DP04_0046PE) %>% 
  mutate(year = "2016") %>% 
  slice(-1)
names(housing_acs_2016)[2] <- "DP04_0045PE"
demographic_acs_2016 <- demographic_acs_2016 %>% 
  select(NAME, DP05_0018PE, DP05_0072PE) %>% 
  mutate(year = "2016") %>% 
  slice(-1)

social_acs_2017 <- social_acs_2017 %>% 
  select(NAME, DP02_0008PE, DP02_0066PE, DP02_0079PE) %>% 
  mutate(year = "2017") %>% 
  slice(-1)
economic_acs_2017 <- economic_acs_2017 %>% 
  select(NAME, DP03_0049PE, DP03_0009PE, DP03_0062E, DP03_0074PE, DP03_0129PE) %>% 
  mutate(year = "2017") %>% 
  slice(-1)
housing_acs_2017 <- housing_acs_2017 %>% 
  select(NAME, DP04_0046PE) %>% 
  mutate(year = "2017") %>% 
  slice(-1)
names(housing_acs_2017)[2] <- "DP04_0045PE"
demographic_acs_2017 <- demographic_acs_2017 %>% 
  select(NAME, DP05_0021PE, DP05_0077PE) %>% 
  mutate(year = "2017") %>% 
  slice(-1)
names(demographic_acs_2017)[2] = "DP05_0018PE"
names(demographic_acs_2017)[3] = "DP05_0072PE"

social_acs_2018 <- social_acs_2018 %>% 
  select(NAME, DP02_0008PE, DP02_0066PE, DP02_0079PE) %>% 
  mutate(year = "2018") %>% 
  slice(-1)
economic_acs_2018 <- economic_acs_2018 %>% 
  select(NAME, DP03_0049PE, DP03_0009PE, DP03_0062E, DP03_0074PE, DP03_0129PE) %>% 
  mutate(year = "2018") %>% 
  slice(-1)
housing_acs_2018 <- housing_acs_2018 %>% 
  select(NAME, DP04_0046PE) %>% 
  mutate(year = "2018") %>% 
  slice(-1)
names(housing_acs_2018)[2] <- "DP04_0045PE"
demographic_acs_2018 <- demographic_acs_2018 %>% 
  select(NAME, DP05_0021PE, DP05_0077PE) %>% 
  mutate(year = "2018") %>% 
  slice(-1)
names(demographic_acs_2018)[2] = "DP05_0018PE"
names(demographic_acs_2018)[3] = "DP05_0072PE"

social_acs_2019 <- social_acs_2019 %>% 
  select(NAME, DP02_0011PE, DP02_0067PE, DP02_0080PE) %>% 
  mutate(year = "2019") %>% 
  slice(-1)
names(social_acs_2019)[2] = "DP02_0008PE"
names(social_acs_2019)[3] = "DP02_0066PE"
names(social_acs_2019)[4] = "DP02_0079PE"
economic_acs_2019 <- economic_acs_2019 %>% 
  select(NAME, DP03_0049PE, DP03_0009PE, DP03_0062E, DP03_0074PE, DP03_0129PE) %>% 
  mutate(year = "2019") %>% 
  slice(-1)
housing_acs_2019 <- housing_acs_2019 %>% 
  select(NAME, DP04_0046PE) %>% 
  mutate(year = "2019") %>% 
  slice(-1)
names(housing_acs_2019)[2] <- "DP04_0045PE"
demographic_acs_2019 <- demographic_acs_2019 %>% 
  select(NAME, DP05_0021PE, DP05_0077PE) %>% 
  mutate(year = "2019") %>% 
  slice(-1)
names(demographic_acs_2019)[2] = "DP05_0018PE"
names(demographic_acs_2019)[3] = "DP05_0072PE"

```

```{r join-datasets, message = FALSE}
social_acs <- full_join(social_acs_2011, social_acs_2012)
social_acs <- full_join(social_acs, social_acs_2013)
social_acs <- full_join(social_acs, social_acs_2014)
social_acs <- full_join(social_acs, social_acs_2015)
social_acs <- full_join(social_acs, social_acs_2016)
social_acs <- full_join(social_acs, social_acs_2017)
social_acs <- full_join(social_acs, social_acs_2018)
social_acs <- full_join(social_acs, social_acs_2019)
economic_acs <- full_join(economic_acs_2011, economic_acs_2012)
economic_acs <- full_join(economic_acs, economic_acs_2013)
economic_acs <- full_join(economic_acs, economic_acs_2014)
economic_acs <- full_join(economic_acs, economic_acs_2015)
economic_acs <- full_join(economic_acs, economic_acs_2016)
economic_acs <- full_join(economic_acs, economic_acs_2017)
economic_acs <- full_join(economic_acs, economic_acs_2018)
economic_acs <- full_join(economic_acs, economic_acs_2019)
demographic_acs <- full_join(demographic_acs_2011, demographic_acs_2012)
demographic_acs <- full_join(demographic_acs, demographic_acs_2013)
demographic_acs <- full_join(demographic_acs, demographic_acs_2014)
demographic_acs <- full_join(demographic_acs, demographic_acs_2015)
demographic_acs <- full_join(demographic_acs, demographic_acs_2016)
demographic_acs <- full_join(demographic_acs, demographic_acs_2017)
demographic_acs <- full_join(demographic_acs, demographic_acs_2018)
demographic_acs <- full_join(demographic_acs, demographic_acs_2019)
housing_acs <- full_join(housing_acs_2011, housing_acs_2012)
housing_acs <- full_join(housing_acs, housing_acs_2013)
housing_acs <- full_join(housing_acs, housing_acs_2014)
housing_acs <- full_join(housing_acs, housing_acs_2015)
housing_acs <- full_join(housing_acs, housing_acs_2016)
housing_acs <- full_join(housing_acs, housing_acs_2017)
housing_acs <- full_join(housing_acs, housing_acs_2018)
housing_acs <- full_join(housing_acs, housing_acs_2019)

```

```{r change-names}
names(social_acs)[2] <- "female_household"
names(social_acs)[3] <- "hs"
names(social_acs)[4] <- "res_stability"
names(demographic_acs)[2] <- "over_18"
names(demographic_acs)[3] <- "white_percent"
names(economic_acs)[2] <- "self_employed"
names(economic_acs)[3] <- "unemployment"
names(economic_acs)[4] <- "median_income"
names(economic_acs)[5] <- "received_snap"
names(economic_acs)[6] <- "child_poverty"
names(housing_acs)[2] <- "owner_occupied"

social_acs <- social_acs %>% 
  slice(-1)

demographic_acs <- demographic_acs %>% 
  slice(-1)

economic_acs <- economic_acs %>% 
  slice(-1)

housing_acs <- housing_acs %>% 
  slice(-1)

```


```{r combine-acs}
full_acs <- full_join(social_acs, demographic_acs, by = c("NAME", "year"), include = TRUE)
full_acs <- full_join(full_acs, economic_acs, by = c("NAME", "year"), include - TRUE) 
full_acs <- full_join(full_acs, housing_acs, by = c("NAME", "year"), include = TRUE)
```

```{r create-pop-density}
full_acs$NAME <- gsub("\\s*\\([^\\)]+\\)","",as.character(full_acs$NAME)) # Code taken from https://stackoverflow.com/questions/24173194/remove-parentheses-and-text-within-from-strings-in-r to remove parentheses
full_acs$NAME <- str_replace(full_acs$NAME, " city, ", ", ")
full_acs$NAME <- str_replace(full_acs$NAME, " municipality, ", ", ")
full_acs$NAME <- str_replace(full_acs$NAME, " village, ", ", ")
full_acs$NAME <- str_replace(full_acs$NAME, " town, ", ", ")
full_acs$NAME <- str_replace(full_acs$NAME, " CDP, ", ", ")
full_acs$NAME <- str_remove(full_acs$NAME, "-Fayette urban county")
full_acs$NAME <- str_remove(full_acs$NAME, "-Davidson metropolitan government")
full_acs$NAME <- str_replace(full_acs$NAME, "/Jefferson County metro government", " Metro")


pop_density <- read.csv("data/pop_density.csv") # set up population density through land area
names(pop_density)[1] <- "NAME"
names(pop_density)[4] <- "land_area"
pop_density <- pop_density %>% 
  select(NAME, land_area) 

pop_density$land_area <- str_remove(pop_density$land_area, ",")

pop_density$NAME <- str_replace(pop_density$NAME, "Louisville", "Louisville Metro")

full_acs <- left_join(full_acs, pop_density, by = "NAME")
full_acs$NAME <- str_replace(full_acs$NAME, "Boise City", "Boise")
```


```{r full-acs}
full_acs <- full_acs %>% 
  mutate(female_household = as.numeric(female_household), 
         hs = as.numeric(hs), 
         res_stability = as.numeric(res_stability), 
         over_18 = as.numeric(over_18), 
         white_percent = as.numeric(white_percent), 
         self_employed = as.numeric(self_employed), 
         unemployment = as.numeric(unemployment), 
         median_income = as.numeric(median_income), 
         received_snap = as.numeric(received_snap), 
         child_poverty = as.numeric(child_poverty), 
         owner_occupied = as.numeric(owner_occupied), 
         year = as.numeric(year), 
         land_area = as.numeric(land_area)) 
full_acs$NAME <- str_replace(full_acs$NAME, "San Buenaventura", "Ventura")
full_acs$NAME <- str_replace(full_acs$NAME, "Washington, District of Columbia", 
                             "Washington, District Of Columbia")
full_acs$NAME <- str_replace(full_acs$NAME, "Savannah, Georgia", 
                             "Savannah-Chatham Metropolitan, Georgia")

full_acs$city <- str_split(full_acs$NAME, ", ", simplify = TRUE)[,1]
full_acs$state <- str_split(full_acs$NAME, ", ", simplify = TRUE)[,2]

```

```{r left-join}
all_crimes$city <- str_replace(all_crimes$city, "Las Vegas Metropolitan Police Department", 
                               "Las Vegas")
all_crimes$city <- str_replace(all_crimes$city, "Charlotte-Mecklenburg", "Charlotte")
all_crimes <- all_crimes %>% 
  mutate(year = as.numeric(year))

full_database <- left_join(all_crimes, full_acs, by = c("city", "state", "year"))
```

```{r add-arbitrary-2020-2021-values}
full_database_for_synth <- full_database %>% 
  filter(is.na(land_area) == FALSE | year >= 2020) %>% 
  arrange(city, state) %>% 
  fill(NAME, .direction = "down") %>% 
  fill(female_household, .direction = "down") %>% 
  fill(hs, .direction = "down") %>% 
  fill(res_stability, .direction = "down") %>% 
  fill(over_18, .direction = "down") %>% 
  fill(white_percent, .direction = "down") %>% 
  fill(self_employed, .direction = "down") %>% 
  fill(unemployment, .direction = "down") %>% 
  fill(median_income, .direction = "down") %>% 
  fill(received_snap, .direction = "down") %>% 
  fill(child_poverty, .direction = "down") %>% 
  fill(owner_occupied, .direction = "down") %>% 
  fill(land_area, .direction = "down") %>% 
  filter()
```


```{r save-work}
write_csv(full_database, "data/crime_database.csv") #finished database creation
write_csv(full_database_for_synth, "data/crime_database_synth.csv")
```

## Wrangling Completed Database

```{r read-full, message = FALSE}
full_database <- read_csv("data/crime_database.csv")
```


```{r fix-damages}
reduced_database <- full_database %>% 
  filter(population >= 50000) %>% 
  filter(is.na(NAME) == FALSE)
```


```{r remove-duplicates, message = FAL}
for_removal <- reduced_database %>% 
  filter(NAME == "Burbank, California") %>% 
  filter(white_percent < 40)

for_removal2 <- reduced_database %>% 
  filter(NAME == "Mesquite, Texas") %>% 
  filter(white_percent == 0.0)
for_removal <- full_join(for_removal, for_removal2)

for_removal2 <- reduced_database %>% 
  filter(NAME == "Mountain View, California") %>% 
  filter(white_percent > 48)
for_removal <- full_join(for_removal, for_removal2)

for_removal2 <- reduced_database %>% 
  filter(NAME == "Plantation, Florida") %>% 
  filter(white_percent > 90)
for_removal <- full_join(for_removal, for_removal2)

reduced_database <- anti_join(reduced_database, for_removal)
```

```{r create-pop-density-variable}
reduced_database <- reduced_database %>% 
  mutate(pop_density = population / land_area) %>% 
  filter(is.na(violent_crime_rate) == FALSE) 

reduced_database <- reduced_database %>% 
  mutate(obs_num = 1:nrow(reduced_database))
```


## Correlation Diagnostics - Linear Models to Replicate Conclusions

### Linear Model Relating Violent Crime Rate to Predictors



I created a full model and a null model, incorporating every predictor outside of population below. 

```{r test-model}
diag1_full <- lm(violent_crime_rate ~ population + pop_density + female_household + hs + res_stability + over_18 + white_percent +
   self_employed + unemployment + median_income + child_poverty + owner_occupied + year, data = reduced_database)

diag1_null <- lm(violent_crime_rate ~ 1, data = reduced_database)

tidy(diag1_full)
```
As we can see, coefficients related to female household percentage, median income, and year were generally nonsignificant with p-values above 0.05. I used a backward selection process using AIC to determine what variables should be excluded.


```{r initial-model-step}
backward_diag1 <- step(diag1_full, direction = "backward") # with AIC
```

Backward selection concluded that median income should be removed from the model.


#### Check Model Conditions

I ran some diagnostics to determine if the linear model was a good fit for the data. Standardized residual plots checked below.

```{r residual-plot-violent-crime}
augment_diag1 <- augment(backward_diag1)

augment_diag1 <- augment_diag1 %>% 
  mutate(obs_num = 1:nrow(augment_diag1))

ggplot(augment_diag1, aes(x = .fitted, y = .std.resid)) + 
  geom_point() + 
  geom_hline(yintercept = 0) + 
  labs(title = "Residual Plot of Linear Violent Crime Model", 
       x = "Fitted Values", 
       y = "Standardized Residual Values") 
```

The residual plot clearly fans out, indicating that the linear model is likely not a good fit for the data. 

I tried a log transformation of the response variable to see if that may mitigate some of the problems with the fan shaped residual plot.

```{r test-model-log}
log_diag1 <- lm(log(violent_crime_rate) ~ population + pop_density + female_household + 
    hs + res_stability + over_18 + white_percent + self_employed + 
    unemployment + child_poverty + owner_occupied + year, data = reduced_database)
log_diag1_augment <- augment(log_diag1)

log_diag1_augment <- log_diag1_augment %>% 
    mutate(obs_num = 1:nrow(log_diag1_augment))

ggplot(log_diag1_augment, aes(x = .fitted, y = .std.resid)) + 
  geom_point() + 
  geom_hline(yintercept = 0) + 
  labs(title = "Residual Plot of Linear Log Transformed Violent Crime Model", 
       x = "Fitted Values", 
       y = "Residual Values")
```


Because the residual plot does not display a clear pattern and the residuals appear to be equally distributed, the log transformed linear model meets the linearity and equal variance assumptions. The log transformation appears largely successful.

Normality Assumption:

```{r norm-assumption}
ggplot(log_diag1, aes(x = .resid)) + 
  geom_histogram() + 
  labs(title = "histogram of Standardized Residuals for Log-Transformed Model", 
       x = "Standardized Residuals", 
       y = "Frequency")
```

Because the histogram of the standardized residuals appears roughly normal, the normality assumption is met. Even if there are some normality violations in the histogram, such violations are more then compensated by the fact that the sample size is greater than 30 within the data.

Independence assumption is partially met. Although there are geographic skews that would influence some crime data in one direction or the other (indicating that residuals are not fully independent of each other), such independent violations are inevitable when dealing with social scientific data. As a result, this study does not attempt to use the most robust version of the linear model but only uses the linear model to inform the incorporation of particular predictors. 

#### Model Diagnostics

Critical Numbers:

```{r}
glance(log_diag1)
```

Model R-squared value is 0.627, indicating that roughly 62.7% of the variation in violent crime rates is explainable by the mentioned predictors. 

Standardized Residual Plot:

```{r std-resid-determine-outliers}
ggplot(data = log_diag1_augment, aes(x = .fitted,y = .std.resid)) +
  geom_point(alpha = 0.7) + 
  geom_hline(yintercept = 0,color = "red") +
  geom_hline(yintercept = -2,color = "black",linetype = "dotted") +
  geom_hline(yintercept = 2,color = "black",linetype = "dotted") +
    geom_hline(yintercept = -3,color = "red",linetype = "dotted") +
  geom_hline(yintercept = 3,color = "red",linetype = "dotted") +
  labs(x = "Predicted", y = "Standardized Residuals",
       title = "Standardized Residuals vs. Predicted") +
  geom_text(aes(label = ifelse(abs(.std.resid) > 2,
                               as.character(obs_num),"")), nudge_x = 4)
```
Clearly, several observations deviate significantly from the linear model.

Cook's Distance:

```{r}
ggplot(data = log_diag1_augment, aes(x = obs_num, y = .cooksd)) + 
  geom_point(alpha = 0.7) + 
  geom_hline(yintercept = 0.5, color = "red", lty = 2) +
  geom_hline(yintercept = 1,color = "red") +
  labs(x = "Observation Number", y = "Cook's Distance",
       title = "Cook's Distance") +
  geom_text(aes(label = ifelse(.cooksd > 1,as.character(obs_num),"")), 
            nudge_x = 2)
```

No observations have a particularly high Cook's Distance, implying that no points are such outliers that they yield disproportionate leverage on the model, nor are they influential if they do yield leverage.

Multicollinearity:

```{r multicollin}
vif(log_diag1) %>% 
  tidy()
```

The model does not present problems with multicollinearity. 

```{r}
tidy(log_diag1)
```

#### Experimental Removal of High Standardized Residuals

The model isolates several key cities with extremely high or low standardized residuals. A standardized residual above 3 is generally extremely problematic, and a standardized residual above 2 is somewhat problematic. To account for cities with similar dynamics to Denver and Colorado Springs, I attempted to exclude cities with extremely high standardized residuals, as that may indicate extremely different structural dynamics at play that cannot be encapsulated by the model. 


```{r experimental-removal}
std_resid_diag1_augment <- log_diag1_augment %>% 
  filter(.std.resid >= 2)
cities_for_removal <- left_join(std_resid_diag1_augment, reduced_database,  by = "obs_num") %>% 
  count(city, sort = TRUE) %>% 
  filter(n > 5)
```

Clearly, many of these cities deviate significantly from the model. I decided to exclude cities that had standardized residuals above 2 at least 5 of the 9 years, meaning that I removed San Francisco, Little Rock, Odessa, Oakland, and Anchorage from the analysis for substantially differing from the dynamics presented by the model.




#### Attempt to Fix Year Residual Skew

Noticing that standardized residuals, on average, seemed to increase substantially as years went on (implying that the model heavily relied on predictors relevant in earlier years and had trouble predicting in later years), I attempted to rectify this by isolating the 2016-2019 time period. This solved the problem to some extent, but it seems the problem still existed (though to a less extreme amount). Re-adding "year" as a variable also did not fix the problem. In the end, because the synthetic control method would be tracking crime rates from 2011-19, I decided to just employ the original model regardless of its systematic residual skews. In sensitivity analysis, I may attempt to use models on just more recent times to isolate further variables that should be included.

```{r limit-by-year}
lm_database <- reduced_database %>% 
  filter(year >= 2016)

lm_database <- lm_database %>% 
  mutate(obs_num = 1:nrow(lm_database)) # Realized that old model had standardized residuals consistently increasing across most jurisdictions as the year increased, indicating that variables of earlier years may be skewing data later. Attempting to fix it by only including years from 2016 or higher.

```

```{r experimental-diag}
experimental_diag1 <- lm(log(violent_crime_rate) ~ pop_density + population + female_household + hs + 
                           res_stability + over_18 + white_percent +
                           self_employed + unemployment + median_income + child_poverty + owner_occupied + year, 
                         data = lm_database)

backward_experiment <- step(experimental_diag1)


```




```{r augment-experimental-diag}
augment <- augment(backward_experiment)
augment <- augment %>% 
  mutate(obs_num = 1:nrow(augment))

lm_database_analysis <- full_join(lm_database, augment, by = "obs_num")

lm_database_analysis %>% 
  filter(city == "Colorado Springs")
```

```{r comp-graph-1}
lm_database_analysis <- lm_database_analysis %>% 
  filter(city == "Aurora" | city == "Boulder" | city == "Colorado Springs" | city == "Denver")

ggplot(lm_database_analysis, aes(x = year.x, y = .std.resid, color = city)) + 
  geom_line()
```

```{r comp-graph-2}
std_resid_diag1_check <- std_resid_diag1_names %>% 
  filter(city == "Boulder" | city == "Aurora" | city == "Denver" | city == "Colorado Springs") %>% 
  filter(state == "Colorado")
ggplot(std_resid_diag1_check, aes(x = year.x, y = .std.resid, color = city)) + 
  geom_line()
```

Ended up rejecting the method used to fix year residual skew because it would exclude vast swaths of data with very little improvement in results.

### Property Crime Predictor Check

I did the same process to determine what variables should be incorporated or excluded for property crimes.
```{r}
diag2_full <- lm(property_crime_rate ~ pop_density + female_household + hs + 
              res_stability + over_18 + white_percent +
   self_employed + unemployment + median_income + child_poverty + 
     owner_occupied, data = reduced_database_property)

diag2_null <- lm(property_crime_rate ~ 1, data = reduced_database_property)

backward_diag2 <- step(diag2_full)
forward_diag2 <- step(diag2_null, direction = "forward", scope = list(
  lower = diag2_null, upper = diag2_full))
```


The backward selection process removed owner-occupied housing. Forward selection also excludes female-led household percents.

#### Check Model Conditions

1. Linearity - The residual plot below also clearly fans, indicating the need for 
```{r residual-plot-violent-crime}
augment_diag2 <- augment(backward_diag2)

augment_diag2 <- augment_diag2 %>% 
  mutate(obs_num = 1:nrow(augment_diag2))

ggplot(augment_diag2, aes(x = .fitted, y = .std.resid)) + 
  geom_point() + 
  geom_hline(yintercept = 0) + 
  labs(title = "Residual Plot of Linear Property Crime Model", 
       x = "Fitted Values", 
       y = "Standardized Residual Values") 
```

## Synthetic Control Modelling for Violent Crimes

```{r}
reduced_database_violent <- reduced_database %>% 
  filter(is.na(violent_crime_rate) == FALSE & is.na(female_household) == FALSE & 
         is.na(hs) == FALSE & is.na(res_stability) == FALSE & is.na(over_18) == FALSE & 
         is.na(white_percent) == FALSE & is.na(self_employed) == FALSE & is.na(unemployment) == FALSE & 
         is.na(median_income) == FALSE & is.na(child_poverty) == FALSE & is.na(owner_occupied) == FALSE
         & is.na(pop_density) == FALSE & is.na(property_crime_rate) == FALSE &
           is.na(received_snap) == FALSE) # %>% 
  # anti_join(cities_for_removal) # removing cities with substantially different dynamics from model.
counts <- reduced_database_violent %>% 
  count(NAME, sort = TRUE)
remove_missing <- counts %>% 
  filter (n < 9)
reduced_database_violent <- anti_join(reduced_database_violent, remove_missing)

```


```{r}
add_numbers_violent <- reduced_database_violent %>% 
  filter(NAME == "Denver, Colorado" | NAME == "Colorado Springs, Colorado" | 
           NAME == "Aurora, Colorado" | NAME == "Fort Collins, Colorado" | 
           state != "Colorado") %>% 
  distinct(NAME) 

add_numbers_violent <- add_numbers_violent %>% 
  mutate(id = 1:nrow(add_numbers_violent))

reduced_database_violent <- full_join(reduced_database_violent, add_numbers_violent, by = "NAME")
```

```{r remove-non-denver-colorado}
reduced_database_violent <- reduced_database_violent %>% 
  filter(NAME == "Denver, Colorado" | NAME == "Colorado Springs, Colorado" | 
           NAME == "Aurora, Colorado" | NAME == "Fort Collins, Colorado" | state != "Colorado") %>% 
  mutate(id = as.numeric(id)) 
reduced_database_violent <- reduced_database_violent %>% 
  mutate(year = as.numeric(year)) 
reduced_database_violent <- as.data.frame(reduced_database_violent)
```

72 73
1:207

195 works

1:75, 78:212 77


```{r}
denver_violent_prep <- dataprep(foo = reduced_database_violent, predictors = 
                                  c("population", "female_household", 
                                                "hs", "res_stability", "over_18", 
                                                "white_percent", "self_employed", 
                                                "unemployment", "median_income", 
                                                "child_poverty"), 
         predictors.op = "mean", dependent = "violent_crime_rate", unit.variable = 
         "id", time.variable = "year", unit.names.variable = "NAME", 
         treatment.identifier = 186, controls.identifier = c(1:184, 187:510), 
         time.predictors.prior = 2011:2018, time.optimize.ssr = 2014:2019, 
         time.plot = 2011:2019)
         
```

200-202 are problematic.




```{r}
synth_denver_violent <- synth(denver_violent_prep)
```

```{r}
path.plot(synth.res = synth_denver_violent,
dataprep.res = denver_violent_prep,
Ylab = c("Violent Crime Rates"),
Xlab = c("Year"),
Legend = c("Denver, CO","Synthetic Denver")
)
```

```{r}
weights <- synth_denver_violent$solution.w
weights <- tibble(weight = weights, id = rownames(weights))
weights <- weights %>% 
  arrange(desc(weight)) %>% 
  mutate(id = as.numeric(id)) %>% 
  full_join(add_numbers_violent, by = "id")
```



Violent Crimes for Denver (all 9 years):

Seattle, Washington (496)
Houston, TX (449)
Fort Smith, AR (14)
Champaign, IL (266)
Ann Arbor, MI (328)

I reran the synthetic control model with just the four cities with data to reweight the averages.

```{r}
prep_test <- dataprep(foo = no_colorado, predictors = c("population", "female_household", 
                                                "hs", "res_stability", "over_18", 
                                                "white_percent", "self_employed", 
                                                "unemployment", "median_income", 
                                                "child_poverty", "owner_occupied"), 
         predictors.op = "mean", dependent = "violent_crime_rate", unit.variable = 
         "id", time.variable = "year", unit.names.variable = "NAME", 
         treatment.identifier = 186, controls.identifier = c(496, 449, 14, 266), 
         time.predictors.prior = 2011:2019, time.optimize.ssr = 2014:2019, 
         time.plot = 2011:2019)
         
```

```{r}
synth_complete_test <- synth(prep_test)
```

```{r}
path.plot(synth.res = synth_complete_test,
dataprep.res = prep,
Ylab = c("Violent Crime Rates"),
Xlab = c("Year"),
Legend = c("Denver, CO","Synthetic Denver")
)
```

```{r}

weights_denver_violent <- synth_complete_test$solution.w
weights_denver_violent <- tibble(weight = weights_denver_violent, id = rownames(weights_denver_violent))

weights_denver_violent <- weights_denver_violent %>% 
  arrange(desc(weight)) %>% 
  mutate(id = as.numeric(id)) %>% 
  full_join(add_numbers_violent, by = "id") %>% 
  slice(1:4)
```

Although the graph comparing the synthetic control and Denver is somewhat worse than the other synthetic control graph, this graph depicts close enough trends between the synthetic control model and Denver to warrant running a test comparing the violent crime rates in both cities over the time period.

#### Colorado Springs


```{r prep-co-springs}
prep_cosprings <- dataprep(foo = reduced_database_violent, predictors = c("pop_density", 
                                                                          "population",
                                                              "female_household", 
                                                "hs", "res_stability", "over_18", 
                                                "white_percent", "self_employed", 
                                                "unemployment", 
                                                "child_poverty", "owner_occupied"), 
         predictors.op = "mean", dependent = "violent_crime_rate", unit.variable = 
         "id", time.variable = "year", unit.names.variable = "NAME", 
         treatment.identifier = 186, controls.identifier = c(1:184, 189:512), 
         time.predictors.prior = 2011:2018, time.optimize.ssr = 2014:2019, 
         time.plot = 2011:2019)
```

```{r synthetic-control-co-springs}
synth_co_springs <- synth(prep_cosprings)
```

```{r plot-synthetic-cosprings}
path.plot(synth.res = synth_co_springs,
dataprep.res = prep_cosprings,
Ylab = c("Violent Crime Rates"),
Xlab = c("Year"),
Legend = c("Colorado Springs","Synthetic Colorado Springs")
)
```

Synthetic Colorado Springs does not appear to closely match CO Springs' trend from 2015 to 2019, although it does somewhat match the trend from 2011 to 2015. Perhaps rerunning the synthetic control with just 2015 to 2019?

```{r}
weights <- synth_co_springs$solution.w
weights <- tibble(weight = weights, id = rownames(weights))

weights <- weights %>% 
  arrange(desc(weight)) %>% 
  mutate(id = as.numeric(id)) %>% 
  full_join(add_numbers_violent, by = "id")
```



Meridian, Idaho - 260
Lawton, Oklahoma - 400
Ann Arbor, Michigan - 328
Chico, California - 36
South Jordan, Utah - 478

```{r prep-co-springs-true}
prep_cosprings_true <- dataprep(foo = reduced_database_violent, predictors = c("pop_density", 
                                                                          "population",
                                                              "female_household", 
                                                "hs", "res_stability", "over_18", 
                                                "white_percent", "self_employed", 
                                                "unemployment", 
                                                "child_poverty", "owner_occupied"), 
         predictors.op = "mean", dependent = "violent_crime_rate", unit.variable = 
         "id", time.variable = "year", unit.names.variable = "NAME", 
         treatment.identifier = 186, controls.identifier = c(205, 246, 435, 381), 
         time.predictors.prior = 2011:2018, time.optimize.ssr = 2012:2014, 
         time.plot = 2011:2019)
```

```{r synthetic-control-co-springs-true}
synth_co_springs_true <- synth(prep_cosprings_true)
```

```{r plot-synthetic-cosprings-reduced}
path.plot(synth.res = synth_co_springs_true,
dataprep.res = prep_cosprings_true,
Ylab = c("Violent Crime Rates"),
Xlab = c("Year"),
Legend = c("Colorado Springs","Synthetic Colorado Springs")
)
```

```{r}
weights <- synth_co_springs_true$solution.w
weights <- tibble(weight = weights, id = rownames(weights))

weights <- weights %>% 
  arrange(desc(weight)) %>% 
  mutate(id = as.numeric(id)) %>% 
  full_join(add_numbers_violent, by = "id")
```
#### Aurora

```{r}
aurora_violent_prep <- dataprep(foo = reduced_database_violent, predictors = 
                                  c("pop_density", "population", "female_household", 
                                                "hs", "res_stability", "over_18", 
                                                "white_percent", "self_employed", 
                                                "unemployment", 
                                                "child_poverty", "owner_occupied"), 
         predictors.op = "mean", dependent = "violent_crime_rate", unit.variable = 
         "id", time.variable = "year", unit.names.variable = "NAME", 
         treatment.identifier = 185, controls.identifier = c(1:184, 189:512), 
         time.predictors.prior = 2011:2018, time.optimize.ssr = 2017:2019, 
         time.plot = 2011:2019)
```





```{r}
synth_aurora_violent <- synth(aurora_violent_prep)
```

```{r}
path.plot(synth.res = synth_aurora_violent,
dataprep.res = aurora_violent_prep,
Ylab = c("Violent Crime Rates"),
Xlab = c("Year"),
Legend = c("Aurora, CO","Synthetic Aurora")
)
```

```{r}
weights_aurora <- synth_aurora_violent$solution.w
weights_aurora <- tibble(weight = weights_aurora, id = rownames(weights_aurora))
weights_aurora <- weights_aurora %>% 
  arrange(desc(weight)) %>% 
  mutate(id = as.numeric(id)) %>% 
  full_join(add_numbers_violent, by = "id")
```

```{r}
aurora_violent_prep_true <- dataprep(foo = reduced_database_violent, predictors = 
                                  c("pop_density", "population", "female_household", 
                                                "hs", "res_stability", "over_18", 
                                                "white_percent", "self_employed", 
                                                "unemployment", 
                                                "child_poverty", "owner_occupied"), 
         predictors.op = "mean", dependent = "violent_crime_rate", unit.variable = 
         "id", time.variable = "year", unit.names.variable = "NAME", 
         treatment.identifier = 185, controls.identifier = c(447, 458, 469), 
         time.predictors.prior = 2011:2018, time.optimize.ssr = 2017:2019, 
         time.plot = 2011:2019)
```





```{r}
synth_aurora_violent_true <- synth(aurora_violent_prep_true)
```

```{r}
path.plot(synth.res = synth_aurora_violent_true,
dataprep.res = aurora_violent_prep_true,
Ylab = c("Violent Crime Rates"),
Xlab = c("Year"),
Legend = c("Aurora, CO","Synthetic Aurora")
)
```

```{r}
weights_aurora <- synth_aurora_violent_true$solution.w
weights_aurora <- tibble(weight = weights_aurora, id = rownames(weights_aurora))
weights_aurora <- weights_aurora %>% 
  arrange(desc(weight)) %>% 
  mutate(id = as.numeric(id)) %>% 
  full_join(add_numbers_violent, by = "id")
```


```{r experimenting-tables}
synth.tables <- synth.tab(dataprep.res = aurora_violent_prep, synth.res = 
                            synth_aurora_violent)

synth.tables$tab.pred
```


## Synthetic Control Modelling for Property Crimes

```{r}
reduced_database_property <- reduced_database %>% 
  filter(is.na(property_crime_rate) == FALSE 
         & is.na(population) == FALSE & 
           is.na(female_household) == FALSE & is.na(hs) == FALSE & 
           is.na(res_stability) == FALSE & is.na(over_18) == FALSE & 
         is.na(white_percent) == FALSE & is.na(self_employed) == FALSE & is.na(unemployment) == FALSE & 
         is.na(median_income) == FALSE & is.na(child_poverty) == FALSE & is.na(owner_occupied) == FALSE
         & is.na(pop_density) == FALSE)
counts <- reduced_database_property %>% 
  count(NAME, sort = TRUE)
remove_missing <- counts %>% 
  filter (n < 9)
reduced_database_property <- anti_join(reduced_database_property, remove_missing)

```



```{r}
add_numbers <- reduced_database_property %>% 
  filter(NAME == "Denver, Colorado" | NAME == "Colorado Springs, Colorado" | state != "Colorado") %>% 
  distinct(NAME) 

add_numbers <- add_numbers %>% 
  mutate(id = 1:nrow(add_numbers))

reduced_database_property <- full_join(reduced_database_property, add_numbers, by = "NAME")
```


```{r remove-non-denver-colorado}
reduced_database_property <- reduced_database_property %>% 
  filter(NAME == "Denver, Colorado" | NAME == "Colorado Springs, Colorado" | state != "Colorado") %>% 
  mutate(id = as.numeric(id)) 
reduced_database_property <- reduced_database_property %>% 
  mutate(year = as.numeric(year)) 
reduced_database_property <- as.data.frame(reduced_database_property)
```


```{r denver-prep}
denver_prop_prep <- dataprep(foo = reduced_database_property,
                             predictors = c("pop_density",  
                                                "hs", "res_stability", "over_18", 
                                                "white_percent", "self_employed", 
                                                "unemployment", "median_income", 
                                                "child_poverty"), 
         predictors.op = "mean", dependent = "property_crime_rate", unit.variable = 
         "id", time.variable = "year", unit.names.variable = "NAME", 
         treatment.identifier = 186, controls.identifier = c(1:184, 187:503), 
         time.predictors.prior = 2011:2018, time.optimize.ssr = 2016:2019, 
         time.plot = 2011:2019)
         
```




```{r}
synth_denver_property <- synth(denver_prop_prep)
```

```{r}
path.plot(synth.res = synth_denver_property,
dataprep.res = denver_prop_prep,
Ylab = c("Property Crime Rates"),
Xlab = c("Year"),
Legend = c("Denver, CO","Synthetic Denver")
)
```

```{r}
weights_denver_prop <- synth_denver_property$solution.w
weights_denver_prop <- tibble(weight = weights_denver_prop, id = rownames(weights_denver_prop))
weights_denver_prop <- weights_denver_prop %>% 
  arrange(desc(weight)) %>% 
  mutate(id = as.numeric(id))
weights_denver_prop <- full_join(weights_denver_prop, add_numbers, by = "id")
```


```{r synth-test-prep}
denver_prop_prep_test <- dataprep(foo = no_colorado1, predictors = c("population", "female_household", 
                                                "hs", "res_stability", "over_18", 
                                                "white_percent", "self_employed", 
                                                "unemployment", "median_income", 
                                                "child_poverty", "owner_occupied"), 
         predictors.op = "mean", dependent = "property_crime_rate", unit.variable = 
         "id", time.variable = "year", unit.names.variable = "NAME", 
         treatment.identifier = 186, controls.identifier = c(466, 266, 512, 14, 449), 
         time.predictors.prior = 2011:2018, time.optimize.ssr = 2016:2019, 
         time.plot = 2011:2019)
```

```{r synth-test}
synth_denver_property_test <- synth(denver_prop_prep_test)
```

```{r}
path.plot(synth.res = synth_denver_property_test,
dataprep.res = denver_prop_prep_test,
Ylab = c("Property Crime Rates"),
Xlab = c("Year"),
Legend = c("Denver, CO","Synthetic Denver")
)
```

```{r}
weights_denver_prop_test <- synth_denver_property_test$solution.w
weights_denver_prop_test <- tibble(weight = weights_denver_prop_test, id = rownames(weights_denver_prop_test))
weights_denver_prop_test <- weights_denver_prop_test %>% 
  arrange(desc(weight)) %>% 
  mutate(id = as.numeric(id))
weights_denver_prop_test <- full_join(weights_denver_prop_test, add_numbers, by = "id")
```

449 - Austin, TX - 0.6936


```{r cspd-prep}
cspd_prop_prep <- dataprep(foo = reduced_database_property, predictors = c("pop_density", 
                                                "hs", "res_stability", "over_18", 
                                                "white_percent", "self_employed", 
                                                "unemployment", "median_income", 
                                                "child_poverty"), 
         predictors.op = "mean", dependent = "property_crime_rate", unit.variable = 
         "id", time.variable = "year", unit.names.variable = "NAME", 
         treatment.identifier = 185, controls.identifier = c(1:184, 187:503), 
         time.predictors.prior = 2011:2018, time.optimize.ssr = 2016:2019, 
         time.plot = 2011:2019)
         
```




```{r}
synth_cspd_property_true <- synth(cspd_prop_prep)
```

```{r}
path.plot(synth.res = synth_cspd_property_true,
dataprep.res = cspd_prop_prep,
Ylab = c("Property Crime Rates"),
Xlab = c("Year"),
Legend = c("Colorado Springs, CO","Synthetic Colorado Springs")
)
```

```{r}
weights_cspd_prop <- synth_cspd_property_true$solution.w
weights_cspd_prop <- tibble(weight = weights_cspd_prop, id = rownames(weights_cspd_prop))
weights_cspd_prop <- weights_cspd_prop %>% 
  arrange(desc(weight)) %>% 
  mutate(id = as.numeric(id)) %>% 
  full_join(add_numbers, by = "id")
```

414 - Clarksville, TN
260 - Meridian, ID
326 - Ann Arbor, MI
472
431
6


### Sensitivity Analysis on CSPD



```{r cspd-filter}
reduced_database_property_cspd <- reduced_database %>% 
  filter(is.na(property_crime_rate) == FALSE 
         & is.na(population) == FALSE & 
           is.na(female_household) == FALSE & is.na(hs) == FALSE & 
           is.na(res_stability) == FALSE & is.na(over_18) == FALSE & 
         is.na(white_percent) == FALSE & is.na(self_employed) == FALSE & is.na(unemployment) == FALSE & 
         is.na(median_income) == FALSE & is.na(child_poverty) == FALSE & 
           is.na(owner_occupied) == FALSE) %>% 
  filter(property_crime_rate >= 2000 & property_crime_rate <= 6000)
counts <- reduced_database_property_cspd %>% 
  count(NAME, sort = TRUE)
remove_missing <- counts %>% 
  filter (n < 9)
reduced_database3 <- anti_join(reduced_database_property_cspd, remove_missing)

add_numbers <- reduced_database3 %>% 
  filter(NAME == "Denver, Colorado" | NAME == "Colorado Springs, Colorado" | state != "Colorado") %>% 
  distinct(NAME) 

add_numbers <- add_numbers %>% 
  mutate(id = 1:nrow(add_numbers))

reduced_database3 <- full_join(reduced_database3, add_numbers, by = "NAME")

no_colorado2 <- reduced_database3 %>% 
  filter(NAME == "Denver, Colorado" | NAME == "Colorado Springs, Colorado" | state != "Colorado") %>% 
  mutate(id = as.numeric(id)) 
no_colorado2 <- no_colorado2 %>% 
  mutate(year = as.numeric(year)) 
no_colorado2 <- as.data.frame(no_colorado2)

```
1:184, 187:531

```{r cspd-prep}
cspd_prop_prep <- dataprep(foo = no_colorado2, predictors = c("population", "female_household", 
                                                "hs", "res_stability", "over_18", 
                                                "white_percent", "self_employed", 
                                                "unemployment", "median_income", 
                                                "child_poverty", "owner_occupied"), 
         predictors.op = "mean", dependent = "property_crime_rate", unit.variable = 
         "id", time.variable = "year", unit.names.variable = "NAME", 
         treatment.identifier = 93, controls.identifier = c(1:92, 95:257), 
         time.predictors.prior = 2011:2018, time.optimize.ssr = 2016:2019, 
         time.plot = 2011:2019)
         
```

```{r}
cspd_prop_prep$X0 <- as.matrix(cspd_prop_prep$X0[,colSums(cspd_prop_prep$X0 != 0) != 0])
cspd_prop_prep$X1 <- as.matrix(cspd_prop_prep$X1[,colSums(cspd_prop_prep$X1 != 0) != 0])
cspd_prop_prep$Z0 <- as.matrix(cspd_prop_prep$Z0[,colSums(cspd_prop_prep$Z0 != 0) != 0])
cspd_prop_prep$Z1 <- as.matrix(cspd_prop_prep$Z1[,colSums(cspd_prop_prep$Z1 != 0) != 0])
cspd_prop_prep$names.and.numbers <- as.matrix(cspd_prop_prep$names.and.numbers[,colSums(cspd_prop_prep$names.and.numbers != 0) != 0])


```


```{r}
synth_cspd_property_sensitivity <- synth(cspd_prop_prep)
```


```{r}
path.plot(synth.res = synth_cspd_property_sensitivity,
dataprep.res = cspd_prop_prep,
Ylab = c("Property Crime Rates"),
Xlab = c("Year"),
Legend = c("Colorado Springs, CO","Synthetic Colorado Springs")
)
```

```{r}
weights_cspd_prop <- synth_cspd_property_sensitivity$solution.w
weights_cspd_prop <- tibble(weight = weights_cspd_prop, id = rownames(weights_cspd_prop))
weights_cspd_prop <- weights_cspd_prop %>% 
  arrange(desc(weight)) %>% 
  mutate(id = as.numeric(id)) %>% 
  full_join(add_numbers, by = "id")
```

21 - Jacksonville, Florida
15 - Walnut Creek, California

```{r save-all}
saveRDS(synth_complete, 
        file = "/Users/andrewqin02/Desktop/R/NPAP/data/denver_violent_synth.Rdata")
saveRDS(synth_complete_test, 
        file = "/Users/andrewqin02/Desktop/R/NPAP/data/denver_violent_true.Rdata")
saveRDS(synth_denver_property, 
        file = "/Users/andrewqin02/Desktop/R/NPAP/data/denver_property_synth.Rdata")
saveRDS(synth_denver_property_test, 
        file = "/Users/andrewqin02/Desktop/R/NPAP/data/denver_property_true.Rdata")
```


## New Synthetic Analysis Incorporating 2020-2021 Data

The UCR published data for the entire year of 2020 and the first 3 quarters of 2021, but unfortunately, did not publish quarterly disaggregated data for 2020. The ideal method would be to track the violent and property crime rates for the pre-treatment years of 2011-first half of 2020 and then track the violent and property crime rates for the post-treatment period of the second half of 2020 and first 3 quarters of 2021. Unfortunately, because we lack this data, I instead chose to use the quarterly UCR report and limit the 2020 data to the first 3 quarters, only incorporating one quarter from the post-treatment years. The only post-treatment crime rate will be from 2021 then. Additionally, because we lack census data, I extrapolated the most recent data (2019) to serve as predictor values for 2020 and 2021. Due to sheer lack of data, this model will not be close to perfect but may provide intriguing insights.

As a part of sensitivity analysis, I will exclude Connecticut, and New Mexico from the analysis, as they all passed qualified immunity legislation, albeit at different times from Colorado.
New York City was not in the dataset to begin with.
No New Mexico data in most jurisdictions from 2020-2021, except for Albuquerque which is sadly missing data from 2019, making it impossible to incorporate regardless.
Only CT jurisdictions should be removed from the analysis.

10, 92, 100

```{r, message = FALSE}
full_database_for_synth <- read_csv("data/crime_database_synth.csv")
```


```{r fix-damages-2}
reduced_database <- full_database_for_synth %>% 
  filter(population >= 85000) %>% 
  filter(is.na(NAME) == FALSE)
```


```{r remove-duplicates-2, message = FALSE}
for_removal <- reduced_database %>% 
  filter(NAME == "Burbank, California") %>% 
  filter(white_percent < 40)

for_removal2 <- reduced_database %>% 
  filter(NAME == "Mesquite, Texas") %>% 
  filter(white_percent == 0.0)
for_removal <- full_join(for_removal, for_removal2)

for_removal2 <- reduced_database %>% 
  filter(NAME == "Mountain View, California") %>% 
  filter(white_percent > 48)
for_removal <- full_join(for_removal, for_removal2)

for_removal2 <- reduced_database %>% 
  filter(NAME == "Plantation, Florida") %>% 
  filter(white_percent > 90)
for_removal <- full_join(for_removal, for_removal2)

reduced_database <- anti_join(reduced_database, for_removal)
```

```{r create-pop-density-variable-2}
reduced_database <- reduced_database %>% 
  mutate(pop_density = population / land_area) %>% 
  filter(is.na(violent_crime_rate) == FALSE) 

reduced_database <- reduced_database %>% 
  mutate(obs_num = 1:nrow(reduced_database))
```


### Violent Crimes


```{r}
reduced_database_violent <- reduced_database %>% 
  filter(is.na(violent_crime_rate) == FALSE & is.na(female_household) == FALSE & 
         is.na(hs) == FALSE & is.na(res_stability) == FALSE & is.na(over_18) == FALSE & 
         is.na(white_percent) == FALSE & is.na(self_employed) == FALSE & is.na(unemployment) == FALSE & 
         is.na(median_income) == FALSE & is.na(child_poverty) == FALSE & is.na(owner_occupied) == FALSE
         & is.na(pop_density) == FALSE & is.na(property_crime_rate) == FALSE 
         & is.na(received_snap) == FALSE) # %>% 
  # anti_join(cities_for_removal) # removing cities with substantially different dynamics from model.
counts <- reduced_database_violent %>% 
  count(city, state, sort = TRUE)
remove_missing <- counts %>% 
  filter (n < 11) #Key difference here - needs to be all 11 years from 2011-2021.
reduced_database_violent <- anti_join(reduced_database_violent, remove_missing)
```

```{r}
add_numbers_violent <- reduced_database_violent %>% 
  filter(NAME == "Denver, Colorado" | NAME == "Colorado Springs, Colorado" | 
           NAME == "Aurora, Colorado" | NAME == "Fort Collins, Colorado" | 
           state != "Colorado") %>% 
  distinct(NAME) 

add_numbers_violent <- add_numbers_violent %>% 
  mutate(id = 1:nrow(add_numbers_violent))

reduced_database_violent <- full_join(reduced_database_violent, add_numbers_violent, by = "NAME")
```

```{r remove-non-denver-colorado-2}
reduced_database_violent <- reduced_database_violent %>% 
  filter(NAME == "Denver, Colorado" | NAME == "Colorado Springs, Colorado" | 
           NAME == "Aurora, Colorado" | NAME == "Fort Collins, Colorado" | state != "Colorado") %>% 
  mutate(id = as.numeric(id)) 
reduced_database_violent <- reduced_database_violent %>% 
  mutate(year = as.numeric(year)) 
reduced_database_violent <- as.data.frame(reduced_database_violent)
```



Denver = 25
Aurora = 5
Colorado Springs = 20

exclude 10, 94
Goes to 96


1:102


#### Denver

```{r}
denver_violent_prep <- dataprep(foo = reduced_database_violent, predictors = 
                                  c("population", "pop_density", # Kept population density
                                    "female_household", 
                                                "hs", "res_stability", "over_18", 
                                                "white_percent", "self_employed", 
                                                "unemployment", 
                                                "child_poverty"), 
         predictors.op = "mean", dependent = "violent_crime_rate", unit.variable = 
         "id", time.variable = "year", unit.names.variable = "NAME", 
         treatment.identifier = 25, controls.identifier = c(1:4, 6:9, 11:19, 21:24, 26:93, 
                                                            95:96), 
         time.predictors.prior = 2011:2020, time.optimize.ssr = 2012:2019, 
         time.plot = 2011:2021)
         
```


```{r}
synth_denver_violent <- synth(denver_violent_prep, optimxmethod = "All")
```

```{r}
path.plot(synth.res = synth_denver_violent,
dataprep.res = denver_violent_prep,
Ylab = c("Violent Crime Rates"),
Xlab = c("Year"),
Legend = c("Denver, CO","Synthetic Denver")
)
```

```{r gaps-plot}

gaps.plot(synth.res = synth_denver_violent,
dataprep.res = denver_violent_prep,
Ylab = "Violent Crime Rate Gaps",
Xlab = "Year"
)
```

When optimizing for 2017 to 2020, the gaps plot does not reveal a significantly greater violent crime jump in Denver compared to other jurisdictions. Similarly, when optimizing for other time periods, there does not appear to be a significantly greater than expected violent crime jump.

#### Colorado Springs

```{r}
cspd_violent_prep <- dataprep(foo = reduced_database_violent, predictors = 
                                  c("pop_density", "population", #Keep both because allows for longer tracking 
                                    "female_household", 
                                                "hs", "res_stability", "over_18", 
                                                "white_percent", "self_employed", 
                                                "unemployment", 
                                                "child_poverty"), 
         predictors.op = "mean", dependent = "violent_crime_rate", unit.variable = 
         "id", time.variable = "year", unit.names.variable = "NAME", 
         treatment.identifier = 20, controls.identifier = c(1:4, 6:9, 11:19, 21:24, 26:93, 
                                                            95:96), 
         time.predictors.prior = 2011:2020, time.optimize.ssr = 2012:2019, 
         time.plot = 2011:2021)
         
```


```{r}
synth_cspd_violent <- synth(cspd_violent_prep, optimxmethod = "All")
```

```{r}
path.plot(synth.res = synth_cspd_violent,
dataprep.res = cspd_violent_prep,
Ylab = c("Violent Crime Rates"),
Xlab = c("Year"),
Legend = c("Colorado Springs, CO","Synthetic Colorado Springs")
)
```

```{r gaps-plot-cspd}

gaps.plot(synth.res = synth_cspd_violent,
dataprep.res = cspd_violent_prep,
Ylab = "Violent Crime Rate Gaps",
Xlab = "Year"
)
```

The synthetic control graph provides no evidence that from 2020 to 2021, Colorado Springs had a significantly greater increase in violent crime compared to the control. The synthetic control also tracks Colorado Springs relatively well, even better than the Denver synthetic control tracks Denver and for longer periods of time as well.

#### Aurora

```{r}
aurora_violent_prep <- dataprep(foo = reduced_database_violent, predictors = 
                                  c("population", "pop_density",
                                    "female_household", 
                                                "hs", "res_stability", "over_18", 
                                                "white_percent", "self_employed", 
                                                "unemployment", 
                                                "child_poverty"), 
         predictors.op = "mean", dependent = "violent_crime_rate", unit.variable = 
         "id", time.variable = "year", unit.names.variable = "NAME", 
         treatment.identifier = 5, controls.identifier = c(1:4, 6:9, 11:19, 21:24, 26:93, 
                                                            95:96), 
         time.predictors.prior = 2011:2020, time.optimize.ssr = 2012:2019, 
         time.plot = 2011:2021)
         
```


```{r}
synth_aurora_violent <- synth(aurora_violent_prep, optimxmethod = "All")
```

```{r}
path.plot(synth.res = synth_aurora_violent,
dataprep.res = aurora_violent_prep,
Ylab = c("Violent Crime Rates"),
Xlab = c("Year"),
Legend = c("Aurora, CO","Synthetic Aurora")
)
```

```{r gaps-plot-aurora}

gaps.plot(synth.res = synth_aurora_violent,
dataprep.res = aurora_violent_prep,
Ylab = "Violent Crime Rate Gaps",
Xlab = "Year"
)
```


#### Fort Collins



### Property Crimes

#### Denver

```{r}
denver_property_prep <- dataprep(foo = reduced_database_violent, predictors = 
                                  c("population", "pop_density", "median_income", 
                                                "hs", "res_stability", "over_18", 
                                                "white_percent", "self_employed", 
                                                "unemployment", 
                                                "child_poverty"), 
         predictors.op = "mean", dependent = "property_crime_rate", unit.variable = 
         "id", time.variable = "year", unit.names.variable = "NAME", 
         treatment.identifier = 25, controls.identifier = c(1:4, 6:9, 11:19, 21:24, 26:93, 
                                                            95:96), 
         time.predictors.prior = 2011:2020, time.optimize.ssr = 2012:2019, 
         time.plot = 2011:2021)
         
```

```{r}
synth_denver_property <- synth(denver_property_prep, optimxmethod = "All")
```

```{r}
path.plot(synth.res = synth_denver_property,
dataprep.res = denver_property_prep,
Ylab = c("Violent Crime Rates"),
Xlab = c("Year"),
Legend = c("Denver, CO","Synthetic Denver")
)
```

```{r gaps-plot}
gaps.plot(synth.res = synth_denver_property,
dataprep.res = denver_property_prep,
Ylab = "Property Crime Rate Gaps",
Xlab = "Year"
)
```

The synthetic control graph does imply the existence of increases in property crime that exceed those of synthetic control. Markedly, past 2019, the amount of property crime incidents substantially increases, far past the control. Will need to run placebo tests to determine the accuracy of this result.

#### Colorado Springs

```{r}
cspd_property_prep <- dataprep(foo = reduced_database_violent, predictors = 
                                  c("population", "pop_density", "median_income", 
                                                "hs", "res_stability", "over_18", 
                                                "white_percent", "self_employed", 
                                                "unemployment", 
                                                "child_poverty"), 
         predictors.op = "mean", dependent = "property_crime_rate", unit.variable = 
         "id", time.variable = "year", unit.names.variable = "NAME", 
         treatment.identifier = 20, controls.identifier = c(1:4, 6:9, 11:19, 21:24, 26:93, 
                                                            95:96), 
         time.predictors.prior = 2011:2020, time.optimize.ssr = 2012:2019, 
         time.plot = 2011:2021)
         
```

```{r}
synth_cspd_property <- synth(cspd_property_prep, optimx = "All")
```

```{r}
path.plot(synth.res = synth_cspd_property,
dataprep.res = cspd_property_prep,
Ylab = c("Property Crime Rates"),
Xlab = c("Year"),
Legend = c("Colorado Springs, CO","Synthetic Colorado Springs")
)
```

```{r gaps-plot}

gaps.plot(synth.res = synth_cspd_property,
dataprep.res = cspd_property_prep,
Ylab = "Property Crime Rate Gaps",
Xlab = "Year", 
Ylim = c(-1000, 1000)
)
```


Markedly, the synthetic control model for Colorado Springs displays no such increase in property crimes. Additionally, the synthetic control follows Colorado Springs' property crime numbers remarkably well (with gaps only hitting a maximum of 400 in terms of property crime rates, far better than the thousands in the context of Denver). The control also follows Colorado Springs' numbers throughout the entire period. 

#### Aurora


```{r}
aurora_property_prep <- dataprep(foo = reduced_database_violent, predictors = 
                                  c("population", "pop_density", "median_income",
                                                "hs", "res_stability", "over_18", 
                                                "white_percent", "self_employed", 
                                                "unemployment", 
                                                "child_poverty"), 
         predictors.op = "mean", dependent = "property_crime_rate", unit.variable = 
         "id", time.variable = "year", unit.names.variable = "NAME", 
         treatment.identifier = 5, controls.identifier = c(1:4, 6:9, 11:19, 21:24, 26:93, 
                                                            95:96), 
         time.predictors.prior = 2011:2020, time.optimize.ssr = 2012:2019, 
         time.plot = 2011:2021)
         
```

```{r}
synth_aurora_property <- synth(aurora_property_prep, optimxmethod = "All")
```

```{r}
path.plot(synth.res = synth_aurora_property,
dataprep.res = aurora_property_prep,
Ylab = c("Violent Crime Rates"),
Xlab = c("Year"),
Legend = c("Aurora, CO","Synthetic Aurora")
)
```

```{r gaps-plot}

gaps.plot(synth.res = synth_aurora_property,
dataprep.res = aurora_property_prep,
Ylab = "Property Crime Rate Gaps",
Xlab = "Year"
)
```

Aurora may also have experienced a greater increase in violent crime compared to the synthetic control. Both Aurora and Denver's property crimes should be tested with placebos.

```{r calculate-mspe}
est <- aurora_property_prep$Y0plot %*% synth_aurora_property$solution.w
est <- est[c(10, 11)]
real <- reduced_database_violent %>% 
  filter(NAME == "Aurora, Colorado" & year >= 2020) %>% 
  select(property_crime_rate) %>% 
  pull()

mspe_ratio <- cvTools::mspe(est, real) / synth_aurora_property$loss.v
mspe_ratio <- mspe_ratio[1]
l <- synth_aurora_property$loss.v
l <- l[1]

```

#### Plot Placebos Property Crimes

```{r gen-placebos}
placebos4 <- generate.placebos(denver_violent_prep, synth_denver_violent) ## Placebos
saveRDS(placebos4, 
       file = "/Users/andrewqin02/Desktop/R/NPAP/data/placebos4.Rdata")

```

```{r denver-placebo-results}
test_results <- SCtools::mspe.test(placebos3)$test
SCtools::mspe.test(placebos3, discard.extreme = TRUE, mspe.limit = 5)$p.val
```

```{r denver-placebo-results}
test_results2 <- SCtools::mspe.test(placebos4)$test
SCtools::mspe.test(placebos4, discard.extreme = TRUE, mspe.limit = 5)$p.val
```

```{r plot-results}
ggplot(test_results, aes(x = MSPE.ratios)) + 
  geom_histogram(binwidth = 2.5) +
  xlim(0, 250) +
  ylim(0, 20) + 
  geom_vline(xintercept = 36.61, color = "red") + 
  geom_vline(xintercept = mspe_ratio, color = "steelblue")
```

I manually find Aurora p-value below, using the MSPE ratio calculated earlier.

```{r test-results-aurora}
test_results_aurora <- test_results %>% 
  filter(unit != "Denver, Colorado") #remove Denver
names(test_results_aurora)[1] <- "ratios"
n <- test_results_aurora %>% 
  filter(ratios >= mspe_ratio) %>% 
  nrow()
n / nrow(test_results_aurora) 
```

P-value without removing jurisdictions with significantly greater MSPEs is 0.04.

```{r p-value-aurora}
extremes <- which(placebos2$mspe.placs >= 5 * l) # l = Aurora loss.v value 
unit.names <- placebos2$names.and.numbers$unit.names[extremes]
unit_names <- tibble(unit = unit.names) # Find unit names for those that qualify as extremes

test_results_aurora_lim <- test_results %>% 
  anti_join(unit_names) %>% 
  filter(unit != "Denver, Colorado")

names(test_results_aurora_lim)[1] <- "ratios"
n <- test_results_aurora_lim %>% 
  filter(ratios >= mspe_ratio) %>% 
  nrow()
n / nrow(test_results_aurora_lim)  # Find p-value again

```


P-value when removing jurisdictions with pre-treatment MSPEs 5x or more greater than the pre-treatment MSPEs 

```{r p-value-cspd}
est2 <- cspd_property_prep$Y0plot %*% synth_cspd_property$solution.w
est2 <- est2[c(10, 11)]
real <- reduced_database_violent %>% 
  filter(NAME == "Colorado Springs, Colorado" & year >= 2020) %>% 
  select(property_crime_rate) %>% 
  pull()

mspe_ratio_cspd <- cvTools::mspe(est2, real) / synth_cspd_property$loss.v
mspe_ratio_cspd <- mspe_ratio_cspd[1]

l_cspd <- synth_cspd_property$loss.v
l_cspd <- l_cspd[1]
extremes <- which(placebos3$mspe.placs >= 5 * l_cspd) # l = Aurora loss.v value 
unit.names <- placebos3$names.and.numbers$unit.names[extremes]
unit_names <- tibble(unit = unit.names) # Find unit names for those that qualify as extremes

test_results_cspd_lim <- test_results %>% 
  anti_join(unit_names) %>% 
  filter(unit != "Denver, Colorado")

names(test_results_cspd_lim)[1] <- "ratios"
n <- test_results_cspd_lim %>% 
  filter(ratios >= mspe_ratio_cspd) %>% 
  nrow()
n / nrow(test_results_cspd_lim)  # Find p-value again

```

P-value is high for Colorado Springs.


pre-treatment MSPE = mspe.placs (loss.v)
loss.v = pre-treatment MSPE of treated unit

post <- subset(tdf$df, year >= tdf$t1)

Notes from experimenting with the SCTools package:
- Possible flaw - included within the post-treatment MSPE is the year of the treatment (2020 in this case) - can experiment to see what happens when we change that year to be only 2021. Very simple fix - will be in new RScript.
- MSPE is calculated by dataprep object$Y0plot %*%  synth object$solution.w to find predicted values (take last 2 and map to y_hat), the 2 real values from reduced_database_violent mapped to y, and then mspe(y, y_hat) / loss.v
- P-values are just calculated by the proportion of MSPEs

Two more generate_placebos commands are needed:
- need to generate placebos over 2011:2019 so that loss.v can be calculated over the whole pre-treatment period, not just the period from 2016:2019 because that skews the data with only 4 years (tho keep the placebos here)
- Generate placebos with pretreatment optimization 2011:2020 and 2020 counts as pretreatment (so the pre-treatment time period would then be 2011:2021). Only 1st 3 quarters of 2020 should be included.


#### Experimentation

```{r}
test_property_prep <- dataprep(foo = reduced_database_violent, predictors = 
                                  c("population", "pop_density", "median_income",
                                                "hs", "res_stability", "over_18", 
                                                "white_percent", "self_employed", 
                                                "unemployment", 
                                                "child_poverty"), 
         predictors.op = "mean", dependent = "property_crime_rate", unit.variable = 
         "id", time.variable = "year", unit.names.variable = "NAME", 
         treatment.identifier = 57, controls.identifier = c(1:4, 6:9, 11:19, 21:24, 26:56, 58:93, 
                                                            95:96), 
         time.predictors.prior = 2011:2020, time.optimize.ssr = 2012:2019, 
         time.plot = 2011:2021)
         
```

```{r}
synth_test_property <- synth(test_property_prep)
```

```{r}
path.plot(synth.res = synth_test_property,
dataprep.res = test_property_prep,
Ylab = c("Violent Crime Rates"),
Xlab = c("Year"),
Legend = c("Madison, WI","Synthetic Madison")
)

# Generate placebos command didn't make a mistake; instead, because the model performs exceptionally well over optimization time period, the pre-MSPE value is exceptionally low. This may be removed from the model.
```


```{r}
SCtools::mspe.test(placebos)
```

```{r}
synth.tables <- synth.tab(dataprep.res = test_property_prep, 
                          synth.res = synth_test_property)
synth.tables$tab.pred
```

